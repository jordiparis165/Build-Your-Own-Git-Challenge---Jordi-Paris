{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jordiparis165/Build-Your-Own-Git-Challenge---Jordi-Paris/blob/main/Copie_de_TDNot%C3%A9__Fraud_Detection_Incremental_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2db2007",
      "metadata": {
        "id": "b2db2007"
      },
      "source": [
        "\n",
        "# Fraud Detection – Incremental Machine Learning Strategies\n",
        "\n",
        "⚠️ **Important**: This practical work is **graded**.\n",
        "\n",
        "The objective of this notebook is to study a **highly imbalanced binary classification problem**\n",
        "and to progressively improve the performance of fraud detection models.\n",
        "\n",
        "Rather than applying advanced techniques directly, you are asked to follow an **incremental learning strategy**:\n",
        "\n",
        "1. Start with a **naïve baseline classifier**\n",
        "2. Introduce **cost-sensitive learning**\n",
        "3. Adapt **evaluation metrics**\n",
        "4. Integrate **Ensemble Learning**\n",
        "5. Integrate **data-level imbalance solutions**\n",
        "6. Explore **more expressive models**\n",
        "\n",
        "At each step, you must **interpret the results**, justify the methodological choices, and discuss their limitations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc3c48ac",
      "metadata": {
        "id": "bc3c48ac"
      },
      "source": [
        "#Credit Card Fraud Detection: Context\n",
        "Credit card transactions have become a cornerstone of modern society, facilitating financial exchanges across the globe. However, with the exponential growth of online payments and electronic transactions, opportunities for fraud in this domain have also multiplied. Ensuring the security of credit card transactions has therefore become a major concern for both consumers and credit card issuers.\n",
        "\n",
        "The importance of detecting fraudulent credit card transactions cannot be overstated. Nobody wants to be the victim of credit card fraud, where unauthorized purchases are made in their name. Consequently, it is imperative that credit card companies are able to quickly recognize and identify fraudulent transactions.\n",
        "\n",
        "In this project, we will explore machine learning methods and algorithms used for detecting fraud in credit card transactions. By applying supervised learning techniques, we aim to identify subtle patterns that may indicate fraudulent activity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ba7a056",
      "metadata": {
        "id": "7ba7a056"
      },
      "source": [
        "\n",
        "# I - Data -processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13daac5f",
      "metadata": {
        "id": "13daac5f"
      },
      "source": [
        "## I.1 - Import the libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0046b187",
      "metadata": {
        "id": "0046b187"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,f1_score, recall_score,precision_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8c379e6",
      "metadata": {
        "id": "a8c379e6"
      },
      "source": [
        "## I.2 - Uploading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf2074b",
      "metadata": {
        "id": "8bf2074b"
      },
      "source": [
        "**Database Description**\n",
        "\n",
        "The dataset contains credit card transactions carried out by European cardholders in September 2013.\n",
        "\n",
        "It includes transactions recorded over a two-day period, with a total of 492 fraud cases out of 284,807 transactions. The dataset is highly imbalanced, as the positive class (fraud) accounts for only 0.172% of all transactions.\n",
        "\n",
        "The features of the transactions are represented by variables V1 through V28, along with the “Amount” and “Time” variables. The target variable “Class” serves as the response variable, taking the value 1 in the case of fraud and 0 otherwise. For security reasons, the original names of the variables have not been disclosed.\n",
        "\n",
        "Before applying classification methods, it is necessary to first analyze the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OQ5iwiNC4aNs",
      "metadata": {
        "id": "OQ5iwiNC4aNs"
      },
      "outputs": [],
      "source": [
        "#céer une connection avec google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5cb4bb1",
      "metadata": {
        "id": "e5cb4bb1"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Data/creditcard.csv\",sep=',', header = 0)\n",
        "\n",
        "#Display the data dimentionality\n",
        "\n",
        "\n",
        "#Display data types\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b779da4b",
      "metadata": {
        "id": "b779da4b"
      },
      "source": [
        "## I.3 - Exploration of Relationships and Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JJ_BHTWeVPFi",
      "metadata": {
        "id": "JJ_BHTWeVPFi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7f4353d5",
      "metadata": {
        "id": "7f4353d5"
      },
      "source": [
        "The database contains 284,807 observations and 31 variables.\n",
        "\n",
        "1. Display the descriptive statistics of the dataset.\n",
        "\n",
        "2. Check if there are some missing values\n",
        "\n",
        "3. Display the boxplots of all variables. Are ther any outliers?\n",
        "\n",
        "4. Display the correlation matrix of the variables. Are there any variables that are strongly correlated?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e88cfe",
      "metadata": {
        "id": "b1e88cfe",
        "outputId": "58a7606a-20e7-49b7-fab8-e52957a4e03f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1            V2            V3            V4  \\\n",
              "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
              "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
              "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
              "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
              "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
              "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
              "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
              "\n",
              "                 V5            V6            V7            V8            V9  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
              "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
              "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
              "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
              "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
              "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
              "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f957baa9",
      "metadata": {
        "id": "f957baa9"
      },
      "outputs": [],
      "source": [
        "#plotting boxplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca734145",
      "metadata": {
        "id": "ca734145"
      },
      "outputs": [],
      "source": [
        "# Correlation\n",
        "# print the correlation coefficients between each variable and the 'Class' variable, sorted in descending order\n",
        "corr_mat=data.corr()\n",
        "res=corr_mat[\"Class\"].sort_values(ascending=False)\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a44737c6",
      "metadata": {
        "id": "a44737c6"
      },
      "source": [
        "## I.4 - Data scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2e1c24a",
      "metadata": {
        "id": "a2e1c24a"
      },
      "source": [
        "To achieve better classification performance, it is necessary to reduce the undesirable effects of outliers by scaling the data to a standard range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3af7040",
      "metadata": {
        "id": "f3af7040"
      },
      "outputs": [],
      "source": [
        "#Data standarization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe9a0bf",
      "metadata": {
        "id": "afe9a0bf",
        "outputId": "76b6d8c2-44ba-46d7-adee-d8a1013437ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "      <th>nTime</th>\n",
              "      <th>nAmount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>...</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.996583</td>\n",
              "      <td>0.244964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.996583</td>\n",
              "      <td>-0.342475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>...</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.996562</td>\n",
              "      <td>1.160686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.996562</td>\n",
              "      <td>0.140534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>...</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.996541</td>\n",
              "      <td>-0.073403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Class     nTime   nAmount  \n",
              "0 -0.189115  0.133558 -0.021053      0 -1.996583  0.244964  \n",
              "1  0.125895 -0.008983  0.014724      0 -1.996583 -0.342475  \n",
              "2 -0.139097 -0.055353 -0.059752      0 -1.996562  1.160686  \n",
              "3 -0.221929  0.062723  0.061458      0 -1.996562  0.140534  \n",
              "4  0.502292  0.219422  0.215153      0 -1.996541 -0.073403  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# verification\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8f16395",
      "metadata": {
        "id": "c8f16395"
      },
      "source": [
        "## I.5 - Splitting the data into input (X) and output (Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c0e297",
      "metadata": {
        "id": "a8c0e297",
        "outputId": "2f69a22e-6522-4ad7-f430-a17ddba1ce3d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(284807, 30) (284807,)\n"
          ]
        }
      ],
      "source": [
        "#Splitting the data into input (X) and output (Y)\n",
        "X = data.drop(columns=[\"Class\"]).values\n",
        "Y = data[\"Class\"].values\n",
        "\n",
        "print(X.shape, Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7315ec0e",
      "metadata": {
        "id": "7315ec0e"
      },
      "source": [
        "\n",
        "###  Display the degree of imbalance in the data\n",
        "\n",
        "1. Quantify imbalance → calculate the proportion of majority (non-fraud) and minority (fraud) classes.\n",
        "\n",
        "2. Visualize imbalance → graph the distribution of classes to highlight the imbalance.\n",
        "\n",
        "3. What do you observe? Propose a solution for this imbalance problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b21a52e7",
      "metadata": {
        "id": "b21a52e7",
        "outputId": "194db04c-1bcb-4ed4-dcbe-5f41f18bb57f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of negative observations: 284315 (99.83% of total)\n",
            "Number of positive observations: 492 (0.17% of total)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#use data.hist to plot the two classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9afc1d83",
      "metadata": {
        "id": "9afc1d83"
      },
      "source": [
        "## I.6 - Split train/test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d85c2e",
      "metadata": {
        "id": "01d85c2e",
        "outputId": "6440054b-ff9f-4131-d14c-fd9c0189b91f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(199364, 30) (85443, 30) (199364,) (85443,)\n"
          ]
        }
      ],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3,random_state=0)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BejOaAC5cy27",
      "metadata": {
        "id": "BejOaAC5cy27"
      },
      "source": [
        "#II- Classification without Balancing using Cost-Sensitive Learning\n",
        "\n",
        "A **First Model: Cost-Sensitive Learning with class_weight** :\n",
        "For this model, you'll train a SVM on the original, imbalanced dataset. The key is to use the class_weight parameter to penalize misclassifications of the minority class. This technique modifies the learning algorithm's cost function without altering the data itself.\n",
        "\n",
        "Evaluate the model by plotting the confusion matrix and the classification Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cuAV0LJidkhL",
      "metadata": {
        "id": "cuAV0LJidkhL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "_aR6cSXUdywq",
      "metadata": {
        "id": "_aR6cSXUdywq"
      },
      "source": [
        "#III- Classification using Ensemble Learning with Cost-Sensitive Learning\n",
        "\n",
        "**Objective**: Explore boosting algorithms and how they can help in handling highly imbalanced datasets.\n",
        "\n",
        "Boosting algorithms (e.g., AdaBoost, Gradient Boosting, XGBoost) iteratively focus on misclassified samples, which often include minority class instances. This makes them naturally more sensitive to class imbalance.\n",
        "\n",
        "1. Explain the principle of Boosting: Each model corrects the errors of the previous one. Misclassified samples (often minority class) get more weight.\n",
        "\n",
        "2. Train two boosting models:\n",
        "\n",
        "##  **AdaBoostClassifier**\n",
        "Class sklearn.ensemble.AdaBoostClassifier(estimator=None, *, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', random_state=None, base_estimator='deprecated')\n",
        "\n",
        "An AdaBoost classifier is a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.\n",
        "\n",
        "\n",
        "## Cost-Sensitive Gradient Boosting with XGBoost\n",
        "\n",
        "In this section, we replace the classical Gradient Boosting model from `scikit-learn`\n",
        "with **XGBoost**, a high-performance gradient boosting library widely used in industry.\n",
        "\n",
        "⚠️ **Important clarification**  \n",
        "XGBoost is **not part of scikit-learn**, but it provides a *scikit-learn compatible API*\n",
        "(`fit`, `predict`, `predict_proba`). This allows us to integrate it seamlessly into\n",
        "our machine learning workflow.\n",
        "\n",
        "### Why XGBoost in this context?\n",
        "\n",
        "Unlike `GradientBoostingClassifier` from `scikit-learn`, XGBoost allows **native cost-sensitive learning**\n",
        "through a dedicated parameter: `scale_pos_weight`.\n",
        "\n",
        "This is particularly important in fraud detection, where:\n",
        "- the minority class (fraud) is extremely rare\n",
        "- misclassifying a fraud (false negative) is much more costly than a false alarm\n",
        "\n",
        "---\n",
        "\n",
        "### Model definition\n",
        "\n",
        "```python\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ratio between majority and minority classes\n",
        "ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    subsample=1.0,\n",
        "    colsample_bytree=1.0,\n",
        "    objective=\"binary:logistic\",\n",
        "    scale_pos_weight=ratio,\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42\n",
        ")\n",
        "```\n",
        "\n",
        "### Explanation of key parameters\n",
        "\n",
        "- `n_estimators`: number of boosted trees\n",
        "- `learning_rate`: contribution of each tree\n",
        "- `max_depth`: complexity of individual trees\n",
        "- `scale_pos_weight`: increases the penalty for misclassifying fraud cases  \n",
        "  → **this is the core cost-sensitive parameter**\n",
        "- `objective=\"binary:logistic\"`: required for binary classification\n",
        "- `eval_metric`: metric optimized during training\n",
        "\n",
        "---\n",
        "\n",
        "### Training the model\n",
        "\n",
        "```python\n",
        "xgb_model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "XGBoost internally adjusts the learning process to focus more on the minority class, without modifying the data distribution.\n",
        "\n",
        "\n",
        "3. **Use Cost-Sensitive Learning:**\n",
        "\n",
        "* Adjust class weights or use scale_pos_weight to penalize misclassification of the minority class.\n",
        "\n",
        "##**Comparing**:\n",
        "Evaluate the models by plotting the confusion matrix and the classification Reports. Choose one or two models for the next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vs_doCK_hqN-",
      "metadata": {
        "id": "Vs_doCK_hqN-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4kPoxxLW5oc0",
      "metadata": {
        "id": "4kPoxxLW5oc0"
      },
      "source": [
        "# IV-  Classification with balanced data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e71b9f8",
      "metadata": {
        "id": "8e71b9f8"
      },
      "source": [
        "To avoid any overfitting or underfitting effects, it is imperative to achieve an optimal balance in data handling. In the next section, we will undertake classification using balanced data, employing two specific balancing techniques:\n",
        "\n",
        "**SMOTE** : A data balancing technique that involves generating synthetic examples for the minority class by creating artificial observations similar to existing samples, in order to balance the class distribution.\n",
        "\n",
        "**B-SMOTE**: A variant of SMOTE that specifically focuses on examples from the minority class located near the decision boundary, generating synthetic data to strengthen these crucial areas for classification.\n",
        "\n",
        "1. Make a copy of the training data `x_train1`\n",
        "2. Create a new balanced training data with  SMOTE (`x_train2`)\n",
        "3. Create an other balanced training date with B-SMOTE (`x_train3`)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "414263a3",
      "metadata": {
        "id": "414263a3"
      },
      "source": [
        "## IV-1  Classification with Random Forest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FYBdrd_Q68Y7",
      "metadata": {
        "id": "FYBdrd_Q68Y7"
      },
      "source": [
        "To create the Random Forest classification models as you've outlined, you'll need to follow a structured approach. Here is a plan to implement each of the three models.\n",
        "\n",
        "\n",
        "2. **Second Model: SMOTE Balanced Data**\n",
        "The second model will use a dataset that has been balanced using the SMOTE (`x_train2`)\n",
        "3. **Third Model: B-SMOTE Balanced Data**\n",
        "The third model is similar to the second, but it uses the Borderline-SMOTE (B-SMOTE) (`x_train3`)\n",
        "\n",
        "3. Build two pipelines:\n",
        "\n",
        "*   One using the best configuration of Random Forest from the previous section with SMMOTE.\n",
        "*   One using the Random Forest with SMOTE.\n",
        "\n",
        "Use ImbPipeline for pipelines (from imblearn.pipeline) that include resampling techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f22f1a8",
      "metadata": {
        "id": "1f22f1a8"
      },
      "source": [
        "## IV- 2- Classification with a Boosting technique\n",
        "Similarly, in this section you will create three classification models using a boosting technique as follows:\n",
        "\n",
        "\n",
        "1.  **First Model:  SMOTE Balanced Data** will use a dataset  balanced with SMOTE (`x_train2`)\n",
        "3.  **Third Model: B-SMOTE Balanced Data** will use a dataset  balanced with B-SMOTE (`x_train3`)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14a93945",
      "metadata": {
        "id": "14a93945"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
        "\n",
        "# create a first copy of x_train\n",
        "# Create a balanced set x_train2 using SMOTE\n",
        "...\n",
        "\n",
        "# Create an other balanced set x_train3 using Borderline SMOTE\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1552095e",
      "metadata": {
        "id": "1552095e"
      },
      "source": [
        "\n",
        "\n",
        "#  Model comparison: which is the best model for the database?\n",
        "\n",
        "Compare the different models according to recall, specificity, F1-score and AUC metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44dHDumBS4JE",
      "metadata": {
        "id": "44dHDumBS4JE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cTlYiXwAUso8",
      "metadata": {
        "id": "cTlYiXwAUso8"
      },
      "source": [
        "#V- Active Learning Integration\n",
        "\n",
        "In this section, we propose to combine Ensemble Learning, Balanced Learning and Active Learning paradigm for Fraud Detection.\n",
        "\n",
        "Use **modAL** to actively select the most informative samples from the training pool.\n",
        "\n",
        "**Steps**:\n",
        "\n",
        "*   Start with a small labeled subset (e.g., 1% of training data)\n",
        "*   Use uncertainty sampling to query new samples\n",
        "*   Train a classifier\n",
        "*   Track performance after each query round"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZiWmd4TjXOss",
      "metadata": {
        "id": "ZiWmd4TjXOss"
      },
      "outputs": [],
      "source": [
        "#Install modAL\n",
        "!pip install modAL-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tz1hkG8BlOF1",
      "metadata": {
        "id": "tz1hkG8BlOF1"
      },
      "outputs": [],
      "source": [
        "rom modAL.models import ActiveLearner\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=FutureWarning,\n",
        "    module='sklearn'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iMu0JX6wlgcp",
      "metadata": {
        "id": "iMu0JX6wlgcp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c8HEiGzblhpg",
      "metadata": {
        "id": "c8HEiGzblhpg"
      },
      "source": [
        "#VI- Anomaly Detection\n",
        "\n",
        "In this final section, we briefly introduce **anomaly detection** as an alternative paradigm to supervised fraud detection.\n",
        "\n",
        "Its purpose is to expose you to the idea that fraud can be detected **without labeled data**, by identifying transactions that significantly deviate from normal behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fyDA3Ir5oE2",
      "metadata": {
        "id": "5fyDA3Ir5oE2"
      },
      "source": [
        "#VI  Discussion"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}